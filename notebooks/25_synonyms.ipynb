{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "To read more about synonyms, checkout the docs [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/synonyms-apis.html).\n",
    "\n",
    "![synonyms_api_docs](../images/synonyms_api_docs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch!\n",
      "{'cluster_name': 'docker-cluster',\n",
      " 'cluster_uuid': 'DlYG5m9gR3upn7qgaYyAJA',\n",
      " 'name': '3d37442d2591',\n",
      " 'tagline': 'You Know, for Search',\n",
      " 'version': {'build_date': '2024-08-05T10:05:34.233336849Z',\n",
      "             'build_flavor': 'default',\n",
      "             'build_hash': '1a77947f34deddb41af25e6f0ddb8e830159c179',\n",
      "             'build_snapshot': False,\n",
      "             'build_type': 'docker',\n",
      "             'lucene_version': '9.11.1',\n",
      "             'minimum_index_compatibility_version': '7.0.0',\n",
      "             'minimum_wire_compatibility_version': '7.17.0',\n",
      "             'number': '8.15.0'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "client_info = es.info()\n",
    "print('Connected to Elasticsearch!')\n",
    "pprint(client_info.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating an index with a custom analyzer that uses a synonym filter to expand terms like \"car\" to include \"automobile\" and \"vehicle.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'index': 'my_synonym_index', 'shards_acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "settings = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"synonym_filter\": {\n",
    "                    \"type\": \"synonym\",\n",
    "                    \"synonyms\": [\n",
    "                        \"car, automobile, vehicle\",\n",
    "                        \"tv, television\",\n",
    "                        \"smartphone, mobile, cell phone\",\n",
    "                        \"jupyter, jupyter notebook, jupyterlab\",\n",
    "                        \"jupiter, mars, earth, venus, mercury, saturn, uranus, neptune => planet\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"synonym_analyzer\": {\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"synonym_filter\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"description\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"synonym_analyzer\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"my_synonym_index\"\n",
    "es.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "response = es.indices.create(index=index_name, body=settings)\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 53092.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'errors': False,\n",
      " 'items': [{'index': {'_id': '70rMLJMBP1iAGUX83frw',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 0,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '8ErMLJMBP1iAGUX83frw',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 1,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '8UrMLJMBP1iAGUX83frw',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 2,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '8krMLJMBP1iAGUX83frw',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 3,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '80rMLJMBP1iAGUX83frw',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 4,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}}],\n",
      " 'took': 1059389}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "operations = []\n",
    "dummy_data = json.load(open(\"../data/synonyms.json\"))\n",
    "for document in tqdm(dummy_data, total=len(dummy_data)):\n",
    "    operations.append({'index': {'_index': index_name}})\n",
    "    operations.append(document)\n",
    "\n",
    "response = es.bulk(operations=operations)\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching with Synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s search for terms that should match synonyms. For example, we’ll search for \"vehicle\" (which should match \"car\" or \"automobile\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results:\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"description\": \"vehicle\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=index_name, body=query)\n",
    "\n",
    "print(\"Search Results:\")\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results:\n",
      "{'description': 'I want to go to Mars.'}\n",
      "{'description': 'I want to go to Venus.'}\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"description\": \"planet\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=index_name, body=query)\n",
    "\n",
    "print(\"Search Results:\")\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding Synonyms for Search-Time Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to apply synonyms only during search (and not while indexing), you can modify the search query analyzer like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'index': 'my_synonym_index', 'shards_acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "settings = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"synonym_filter\": {\n",
    "                    \"type\": \"synonym\",\n",
    "                    \"synonyms\": [\n",
    "                        \"car, automobile, vehicle\",\n",
    "                        \"tv, television\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"index_analyzer\": {\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\"lowercase\"]\n",
    "                },\n",
    "                \"search_analyzer\": {\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\"lowercase\", \"synonym_filter\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"description\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"index_analyzer\",\n",
    "                \"search_analyzer\": \"search_analyzer\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.delete(index=index_name)\n",
    "response = es.indices.create(index=index_name, body=settings)\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 188932.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'errors': False,\n",
      " 'items': [{'index': {'_id': '9ErOLJMBP1iAGUX81PpM',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 0,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '9UrOLJMBP1iAGUX81PpM',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 1,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '9krOLJMBP1iAGUX81PpM',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 2,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '90rOLJMBP1iAGUX81PpM',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 3,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '-ErOLJMBP1iAGUX81PpM',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 4,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}}],\n",
      " 'took': 1188016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "operations = []\n",
    "dummy_data = json.load(open(\"../data/synonyms.json\"))\n",
    "for document in tqdm(dummy_data, total=len(dummy_data)):\n",
    "    operations.append({'index': {'_index': index_name}})\n",
    "    operations.append(document)\n",
    "\n",
    "response = es.bulk(operations=operations)\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results (Search-time synonyms):\n",
      "{'description': 'I love my car and television.'}\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"description\": \"vehicle\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=index_name, body=query)\n",
    "\n",
    "print(\"Search Results (Search-time synonyms):\")\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elastic_search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "To read more about the ingest pipeline, checkout the docs [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/ingest.html).\n",
    "\n",
    "![ingest_pipeline_docs](../images/ingest_pipeline_docs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch!\n",
      "{'cluster_name': 'docker-cluster',\n",
      " 'cluster_uuid': 'DlYG5m9gR3upn7qgaYyAJA',\n",
      " 'name': '3d37442d2591',\n",
      " 'tagline': 'You Know, for Search',\n",
      " 'version': {'build_date': '2024-08-05T10:05:34.233336849Z',\n",
      "             'build_flavor': 'default',\n",
      "             'build_hash': '1a77947f34deddb41af25e6f0ddb8e830159c179',\n",
      "             'build_snapshot': False,\n",
      "             'build_type': 'docker',\n",
      "             'lucene_version': '9.11.1',\n",
      "             'minimum_index_compatibility_version': '7.0.0',\n",
      "             'minimum_wire_compatibility_version': '7.17.0',\n",
      "             'number': '8.15.0'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "client_info = es.info()\n",
    "print('Connected to Elasticsearch!')\n",
    "pprint(client_info.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "response = es.ingest.put_pipeline(\n",
    "    id='lowercase_pipeline',\n",
    "    description='This pipeline transforms the text to lowercase',\n",
    "    processors=[\n",
    "        {\n",
    "            \"lowercase\": {\n",
    "                \"field\": \"text\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lowercase_pipeline': {'description': 'This pipeline transforms the text to '\n",
      "                                       'lowercase',\n",
      "                        'processors': [{'lowercase': {'field': 'text'}}]}}\n"
     ]
    }
   ],
   "source": [
    "response = es.ingest.get_pipeline(id='lowercase_pipeline')\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "response = es.ingest.delete_pipeline(id='lowercase_pipeline')\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulate method allows you to give the pipeline fake data just to test if it is working or not. This is usually done before applying the pipeline to your real index and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "response = es.ingest.put_pipeline(\n",
    "    id='lowercase_pipeline',\n",
    "    description='This pipeline transforms the text to lowercase',\n",
    "    processors=[\n",
    "        {\n",
    "            \"lowercase\": {\n",
    "                \"field\": \"text\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the docs list, we are providing some test data. After executing the cell, nothing will be indexed. You will just get back how the documents will look like after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'docs': [{'doc': {'_id': '1',\n",
      "                   '_index': 'my_index',\n",
      "                   '_ingest': {'timestamp': '2024-10-30T07:20:35.164171477Z'},\n",
      "                   '_source': {'text': 'hello world'},\n",
      "                   '_version': '-3'}}]}\n"
     ]
    }
   ],
   "source": [
    "response = es.ingest.simulate(\n",
    "    id='lowercase_pipeline',\n",
    "    docs=[\n",
    "        {\n",
    "            \"_index\": \"my_index\",\n",
    "            \"_id\": \"1\",\n",
    "            \"_source\": {\n",
    "                \"text\": \"HELLO WORLD\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the data and make the text uppercased to see if the `lowercase_pipeline` will be executed before indexing the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Sample Title 1',\n",
       "  'text': 'THIS IS THE FIRST SAMPLE DOCUMENT TEXT.',\n",
       "  'created_on': '2024-09-22'},\n",
       " {'title': 'Sample Title 2',\n",
       "  'text': 'HERE IS ANOTHER EXAMPLE OF A DOCUMENT.',\n",
       "  'created_on': '2024-09-24'},\n",
       " {'title': 'Sample Title 3',\n",
       "  'text': 'THE CONTENT OF THE THIRD DOCUMENT GOES HERE.',\n",
       "  'created_on': '2024-09-24'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dummy_data = json.load(open(\"../data/dummy_data.json\"))\n",
    "for i, document in enumerate(dummy_data):\n",
    "    uppercased_text = document['text'].upper()\n",
    "    document['text'] = uppercased_text\n",
    "    dummy_data[i] = document\n",
    "\n",
    "dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'my_index'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index='my_index', ignore_unavailable=True)\n",
    "es.indices.create(index='my_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we pass the `lowercase_pipeline` to the bulk method. It will perform the transformations before indexing the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'errors': False,\n",
      " 'ingest_took': 13,\n",
      " 'items': [{'index': {'_id': 's0tN3JIBEY4rCUA-oBxn',\n",
      "                      '_index': 'my_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 0,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': 'tEtN3JIBEY4rCUA-oBxq',\n",
      "                      '_index': 'my_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 1,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': 'tUtN3JIBEY4rCUA-oBxq',\n",
      "                      '_index': 'my_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 2,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}}],\n",
      " 'took': 2762990}\n"
     ]
    }
   ],
   "source": [
    "operations = []\n",
    "for document in dummy_data:\n",
    "    operations.append({'index': {'_index': 'my_index'}})\n",
    "    operations.append(document)\n",
    "\n",
    "response = es.bulk(operations=operations, pipeline='lowercase_pipeline')\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After indexing the documents, we can see that the `text` field for all documents has been lowercased. This indicates the pipeline did run with no issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Sample Title 1', 'created_on': '2024-09-22', 'text': 'this is the first sample document text.'}\n",
      "{'title': 'Sample Title 2', 'created_on': '2024-09-24', 'text': 'here is another example of a document.'}\n",
      "{'title': 'Sample Title 3', 'created_on': '2024-09-24', 'text': 'the content of the third document goes here.'}\n"
     ]
    }
   ],
   "source": [
    "response = es.search(index='my_index')\n",
    "hits = response.body['hits']['hits']\n",
    "\n",
    "for hit in hits:\n",
    "    print(hit['_source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Not handling the failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, we donâ€™t handle failures with `ignore_failure` or `on_failure`. Instead, the pipeline will raise an exception, halting execution of any further processes, and the document will not be indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "response = es.ingest.put_pipeline(\n",
    "    id='pipeline_1',\n",
    "    description='Pipeline with multiple transformations',\n",
    "    processors=[\n",
    "        {\n",
    "            \"lowercase\": {\n",
    "                \"field\": \"text\",\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"set\": {\n",
    "                \"field\": \"text\",\n",
    "                \"value\": \"CHANGED BY PIPELINE\",\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "BadRequestError(400, 'illegal_argument_exception', 'field [text] not present as part of path [text]')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m document \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample Title 4\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated_on\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-09-25\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m }\n\u001b[0;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmy_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpipeline_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocument\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m pprint(response\u001b[38;5;241m.\u001b[39mbody)\n",
      "File \u001b[0;32m~/anaconda3/envs/elastic_search/lib/python3.11/site-packages/elasticsearch/_sync/client/utils.py:446\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/elastic_search/lib/python3.11/site-packages/elasticsearch/_sync/client/__init__.py:2428\u001b[0m, in \u001b[0;36mElasticsearch.index\u001b[0;34m(self, index, document, body, id, error_trace, filter_path, human, if_primary_term, if_seq_no, op_type, pipeline, pretty, refresh, require_alias, routing, timeout, version, version_type, wait_for_active_shards)\u001b[0m\n\u001b[1;32m   2426\u001b[0m __body \u001b[38;5;241m=\u001b[39m document \u001b[38;5;28;01mif\u001b[39;00m document \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m body\n\u001b[1;32m   2427\u001b[0m __headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m-> 2428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   2429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m__method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2430\u001b[0m \u001b[43m    \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_parts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__path_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/elastic_search/lib/python3.11/site-packages/elasticsearch/_sync/client/_base.py:271\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_request\u001b[39m(\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    257\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m     path_parts: Optional[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    265\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ApiResponse[Any]:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_otel\u001b[38;5;241m.\u001b[39mspan(\n\u001b[1;32m    267\u001b[0m         method,\n\u001b[1;32m    268\u001b[0m         endpoint_id\u001b[38;5;241m=\u001b[39mendpoint_id,\n\u001b[1;32m    269\u001b[0m         path_parts\u001b[38;5;241m=\u001b[39mpath_parts \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    270\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m otel_span:\n\u001b[0;32m--> 271\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43motel_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43motel_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m         otel_span\u001b[38;5;241m.\u001b[39mset_elastic_cloud_metadata(response\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/elastic_search/lib/python3.11/site-packages/elasticsearch/_sync/client/_base.py:352\u001b[0m, in \u001b[0;36mBaseClient._perform_request\u001b[0;34m(self, method, path, params, headers, body, otel_span)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    350\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[38;5;241m.\u001b[39mget(meta\u001b[38;5;241m.\u001b[39mstatus, ApiError)(\n\u001b[1;32m    353\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage, meta\u001b[38;5;241m=\u001b[39mmeta, body\u001b[38;5;241m=\u001b[39mresp_body\n\u001b[1;32m    354\u001b[0m     )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verified_elasticsearch:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[0;31mBadRequestError\u001b[0m: BadRequestError(400, 'illegal_argument_exception', 'field [text] not present as part of path [text]')"
     ]
    }
   ],
   "source": [
    "document = {\n",
    "    'title': 'Sample Title 4',\n",
    "    'created_on': '2024-09-25',\n",
    "}\n",
    "\n",
    "response = es.index(\n",
    "    index='my_index',\n",
    "    pipeline='pipeline_1',\n",
    "    body=document\n",
    ")\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Handling the failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle the failures, we use `ignore_failure` or define an `on_failure` block. With `ignore_failure`, the pipeline will skip over the failed step and continue executing subsequent processes without interrupting the flow, allowing other documents to be indexed.\n",
    "\n",
    "Alternatively, with `on_failure`, we can specify custom error-handling steps, such as logging the error, retrying, or sending notifications, ensuring the pipeline proceeds even if one step encounters an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "response = es.ingest.put_pipeline(\n",
    "    id='pipeline_2',\n",
    "    description='Pipeline with multiple transformations, handling and ignoring failures',\n",
    "    processors=[\n",
    "        {\n",
    "            \"lowercase\": {\n",
    "                \"field\": \"text\",\n",
    "                \"on_failure\": [\n",
    "                    {\n",
    "                        \"set\": {\n",
    "                            \"field\": \"text\",\n",
    "                            \"value\": \"FAILED TO LOWERCASE\",\n",
    "                            \"ignore_failure\": True,\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"set\": {\n",
    "                \"field\": \"new_field\",\n",
    "                \"value\": \"ADDED BY PIPELINE\",\n",
    "                \"ignore_failure\": True,\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'tktR3JIBEY4rCUA-DRw2',\n",
      " '_index': 'my_index',\n",
      " '_primary_term': 1,\n",
      " '_seq_no': 3,\n",
      " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
      " '_version': 1,\n",
      " 'result': 'created'}\n"
     ]
    }
   ],
   "source": [
    "document = {\n",
    "    'title': 'Sample Title 4',\n",
    "    'created_on': '2024-09-25',\n",
    "}\n",
    "\n",
    "response = es.index(\n",
    "    index='my_index',\n",
    "    pipeline='pipeline_2',\n",
    "    body=document\n",
    ")\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Sample Title 1', 'created_on': '2024-09-22', 'text': 'this is the first sample document text.'}\n",
      "{'title': 'Sample Title 2', 'created_on': '2024-09-24', 'text': 'here is another example of a document.'}\n",
      "{'title': 'Sample Title 3', 'created_on': '2024-09-24', 'text': 'the content of the third document goes here.'}\n",
      "{'text': 'FAILED TO LOWERCASE', 'title': 'Sample Title 4', 'created_on': '2024-09-25', 'new_field': 'ADDED BY PIPELINE'}\n"
     ]
    }
   ],
   "source": [
    "response = es.search(index='my_index')\n",
    "hits = response.body['hits']['hits']\n",
    "for hit in hits:\n",
    "    print(hit['_source'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elastic_search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
